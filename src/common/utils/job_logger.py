"""
Job Logger - íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì „ì²´ ê¸°ë¡ ì‹œìŠ¤í…œ (v6.2)

ë¸”ë™ë°•ìŠ¤ ë°©ì§€ë¥¼ ìœ„í•œ ìƒì„¸ ê¸°ë¡ ì‹œìŠ¤í…œ
ëª¨ë“  ë‹¨ê³„ì˜ ì‚°ì¶œë¬¼, ì—ì´ì „íŠ¸ ëŒ€í™”, íŒë‹¨ ê·¼ê±°, LLM ë‹µë³€ì„ Job ID ê¸°ë°˜ í´ë”ì— ì €ì¥

Job ID í˜•ì‹: {timestamp}_{domain}_{numbering}
ì˜ˆ: 20260113_143052_retail_001

=== ì €ì¥ êµ¬ì¡° ===

data/storage/                      # ìƒì„¸ ê²°ê³¼ë¬¼ (ë¸”ë™ë°•ìŠ¤ ë°©ì§€)
â””â”€â”€ {job_id}/
    â”œâ”€â”€ job_metadata.json          # Job ë©”íƒ€ë°ì´í„°
    â”œâ”€â”€ pipeline.log               # ì´ Jobì˜ ìƒì„¸ ì‹¤í–‰ ë¡œê·¸
    â”œâ”€â”€ phase1_discovery/          # Phase 1 ì—ì´ì „íŠ¸ ìƒì„¸
    â”‚   â”œâ”€â”€ data_analyst.json      # ì‹¤í–‰ ê²°ê³¼ + íŒë‹¨ ê·¼ê±°
    â”‚   â”œâ”€â”€ tda_expert.json
    â”‚   â”œâ”€â”€ schema_analyst.json
    â”‚   â”œâ”€â”€ value_matcher.json
    â”‚   â”œâ”€â”€ entity_classifier.json
    â”‚   â””â”€â”€ relationship_detector.json
    â”œâ”€â”€ phase2_refinement/         # Phase 2 ì—ì´ì „íŠ¸ ìƒì„¸
    â”‚   â”œâ”€â”€ ontology_architect.json
    â”‚   â”œâ”€â”€ conflict_resolver.json
    â”‚   â”œâ”€â”€ quality_judge.json
    â”‚   â””â”€â”€ semantic_validator.json
    â”œâ”€â”€ phase3_governance/         # Phase 3 ì—ì´ì „íŠ¸ ìƒì„¸
    â”‚   â”œâ”€â”€ governance_strategist.json
    â”‚   â”œâ”€â”€ action_prioritizer.json
    â”‚   â”œâ”€â”€ risk_assessor.json
    â”‚   â””â”€â”€ policy_generator.json
    â”œâ”€â”€ llm_calls/
    â”‚   â””â”€â”€ llm_calls.jsonl        # ëª¨ë“  LLM í˜¸ì¶œ ê¸°ë¡ (í”„ë¡¬í”„íŠ¸ + ì‘ë‹µ)
    â”œâ”€â”€ conversations/             # ì—ì´ì „íŠ¸ ê°„ ëŒ€í™”/í•©ì˜ ê³¼ì •
    â”‚   â””â”€â”€ consensus_rounds.json
    â”œâ”€â”€ thinking/                  # ì—ì´ì „íŠ¸ ì‚¬ê³  ê³¼ì •
    â”‚   â””â”€â”€ {agent}_thinking.jsonl
    â”œâ”€â”€ reasoning_chains/          # ì¶”ë¡  ì²´ì¸
    â”‚   â””â”€â”€ chain_*.json
    â”œâ”€â”€ artifacts/                 # ìµœì¢… ê²°ê³¼ë¬¼
    â”‚   â”œâ”€â”€ ontology.json
    â”‚   â”œâ”€â”€ insights.json
    â”‚   â”œâ”€â”€ governance_decisions.json
    â”‚   â”œâ”€â”€ knowledge_graph.json
    â”‚   â”œâ”€â”€ evidence_chain.json
    â”‚   â””â”€â”€ predictive_insights.json
    â””â”€â”€ summary.json               # ì‹¤í–‰ ìš”ì•½

Logs/                              # ì‹œìŠ¤í…œ ë¡œê·¸ (ì§„í–‰í˜„í™©)
â”œâ”€â”€ ontoloty.log                   # ë©”ì¸ ì‹œìŠ¤í…œ ë¡œê·¸
â””â”€â”€ pipeline_YYYYMMDD.log          # ì¼ë³„ ì§„í–‰ ë¡œê·¸
"""

import json
import logging
import os
import threading
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional
from dataclasses import dataclass, field, asdict
from enum import Enum


class LogLevel(str, Enum):
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class PhaseType(str, Enum):
    DISCOVERY = "phase1_discovery"
    REFINEMENT = "phase2_refinement"
    GOVERNANCE = "phase3_governance"


class ThinkingType(str, Enum):
    """ì‚¬ê³  ìœ í˜•"""
    ANALYSIS = "analysis"           # ë°ì´í„° ë¶„ì„
    REASONING = "reasoning"         # ì¶”ë¡ /ë…¼ë¦¬ì  ì‚¬ê³ 
    HYPOTHESIS = "hypothesis"       # ê°€ì„¤ ìˆ˜ë¦½
    EVALUATION = "evaluation"       # í‰ê°€/íŒë‹¨
    DECISION = "decision"           # ì˜ì‚¬ê²°ì •
    REFLECTION = "reflection"       # ë°˜ì„±/ì¬ê²€í† 
    PLANNING = "planning"           # ê³„íš ìˆ˜ë¦½
    INSIGHT = "insight"             # ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    QUESTION = "question"           # ì§ˆë¬¸/ì˜ë¬¸ì 
    CONCLUSION = "conclusion"       # ê²°ë¡  ë„ì¶œ


@dataclass
class ThinkingRecord:
    """ì—ì´ì „íŠ¸ ì‚¬ê³  ê³¼ì • ê¸°ë¡"""
    timestamp: str
    thinking_type: str              # ThinkingType value
    content: str                    # ì‚¬ê³  ë‚´ìš©
    context: Dict[str, Any] = field(default_factory=dict)  # ì‚¬ê³  ì»¨í…ìŠ¤íŠ¸
    confidence: Optional[float] = None  # í™•ì‹ ë„ (0.0-1.0)
    evidence: List[str] = field(default_factory=list)  # ê·¼ê±°
    related_data: Dict[str, Any] = field(default_factory=dict)  # ê´€ë ¨ ë°ì´í„°


@dataclass
class ReasoningChain:
    """ì¶”ë¡  ì²´ì¸ (ì—¬ëŸ¬ ì‚¬ê³  ë‹¨ê³„ì˜ ì—°ê²°)"""
    chain_id: str
    agent_name: str
    started_at: str
    goal: str                       # ì¶”ë¡  ëª©í‘œ
    completed_at: Optional[str] = None
    steps: List[ThinkingRecord] = field(default_factory=list)
    final_conclusion: Optional[str] = None
    confidence: Optional[float] = None
    success: bool = True


@dataclass
class LLMCallRecord:
    """LLM í˜¸ì¶œ ê¸°ë¡ (v5.1 - ì‚¬ê³  ê³¼ì • í¬í•¨)"""
    timestamp: str
    agent_name: str
    model: str
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    latency_ms: float
    messages: List[Dict[str, str]]
    response: str
    success: bool
    error: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    # v5.1: ì‚¬ê³  ê³¼ì • ê´€ë ¨ í•„ë“œ
    purpose: Optional[str] = None           # LLM í˜¸ì¶œ ëª©ì 
    thinking_before: Optional[str] = None   # í˜¸ì¶œ ì „ ì—ì´ì „íŠ¸ì˜ ìƒê°
    thinking_after: Optional[str] = None    # í˜¸ì¶œ í›„ ì—ì´ì „íŠ¸ì˜ í•´ì„
    extracted_insights: List[str] = field(default_factory=list)  # ì¶”ì¶œëœ ì¸ì‚¬ì´íŠ¸


@dataclass
class AgentExecutionRecord:
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ê¸°ë¡ (v5.1 - ì‚¬ê³  ê³¼ì • í¬í•¨)"""
    agent_name: str
    agent_type: str
    phase: str
    started_at: str
    completed_at: Optional[str] = None
    duration_ms: Optional[float] = None
    todo_id: Optional[str] = None
    input_data: Dict[str, Any] = field(default_factory=dict)
    output_data: Dict[str, Any] = field(default_factory=dict)
    llm_calls: List[str] = field(default_factory=list)  # LLM call IDs
    logs: List[Dict[str, Any]] = field(default_factory=list)
    success: bool = True
    error: Optional[str] = None
    # v5.1: ì‚¬ê³  ê³¼ì • ê´€ë ¨ í•„ë“œ
    thinking_process: List[ThinkingRecord] = field(default_factory=list)  # ì‚¬ê³  ê³¼ì •
    reasoning_chains: List[str] = field(default_factory=list)  # ì¶”ë¡  ì²´ì¸ IDs
    key_decisions: List[Dict[str, Any]] = field(default_factory=list)  # ì£¼ìš” ê²°ì •ë“¤
    analysis_summary: Optional[str] = None  # ë¶„ì„ ìš”ì•½


@dataclass
class JobMetadata:
    """Job ë©”íƒ€ë°ì´í„°"""
    job_id: str
    domain: str
    started_at: str
    completed_at: Optional[str] = None
    status: str = "running"
    total_agents: int = 0
    completed_agents: int = 0
    total_llm_calls: int = 0
    total_tokens: int = 0
    input_tables: List[str] = field(default_factory=list)
    config: Dict[str, Any] = field(default_factory=dict)


class JobLogger:
    """
    Job ê¸°ë°˜ ë¡œê¹… ì‹œìŠ¤í…œ

    íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì˜ ëª¨ë“  ì‚°ì¶œë¬¼ì„ Job ID í´ë”ì— ì €ì¥
    """

    _instance: Optional["JobLogger"] = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        """Singleton pattern"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(
        self,
        base_dir: str = "./data/storage",
        domain: Optional[str] = None,
    ):
        # Singletonì´ë¯€ë¡œ ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš° skip
        if hasattr(self, "_initialized") and self._initialized:
            return

        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)

        self.current_job_id: Optional[str] = None
        self.current_job_dir: Optional[Path] = None
        self.metadata: Optional[JobMetadata] = None

        self._llm_call_counter = 0
        self._agent_records: Dict[str, AgentExecutionRecord] = {}
        self._file_logger: Optional[logging.Logger] = None
        self._llm_file: Optional[Path] = None

        self._initialized = True

    @classmethod
    def get_instance(cls) -> "JobLogger":
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    @classmethod
    def reset_instance(cls):
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹ (í…ŒìŠ¤íŠ¸ìš©)"""
        cls._instance = None

    def _generate_job_id(self, domain: str) -> str:
        """Job ID ìƒì„±: timestamp_domain_numbering"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ê°™ì€ ë‚ ì§œ/ë„ë©”ì¸ì˜ ê¸°ì¡´ job ìˆ˜ í™•ì¸
        pattern = f"{timestamp[:8]}_*_{domain}_*"
        existing = list(self.base_dir.glob(pattern))
        numbering = len(existing) + 1

        return f"{timestamp}_{domain}_{numbering:03d}"

    def start_job(
        self,
        domain: str,
        input_tables: List[str],
        config: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        ìƒˆ Job ì‹œì‘

        Args:
            domain: ì‚°ì—… ë„ë©”ì¸ (retail, healthcare, manufacturing ë“±)
            input_tables: ì…ë ¥ í…Œì´ë¸” ëª©ë¡
            config: íŒŒì´í”„ë¼ì¸ ì„¤ì •

        Returns:
            job_id
        """
        # ê¸°ì¡´ jobì´ ìˆìœ¼ë©´ ì¢…ë£Œ
        if self.current_job_id:
            self.end_job()

        # Job ID ìƒì„±
        self.current_job_id = self._generate_job_id(domain)
        self.current_job_dir = self.base_dir / self.current_job_id

        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        self._create_directory_structure()

        # ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
        self.metadata = JobMetadata(
            job_id=self.current_job_id,
            domain=domain,
            started_at=datetime.now().isoformat(),
            input_tables=input_tables,
            config=config or {},
        )
        self._save_metadata()

        # íŒŒì¼ ë¡œê±° ì„¤ì •
        self._setup_file_logger()

        # LLM í˜¸ì¶œ íŒŒì¼ ì´ˆê¸°í™”
        self._llm_file = self.current_job_dir / "llm_calls" / "llm_calls.jsonl"

        self.log_info(f"Job started: {self.current_job_id}")
        self.log_info(f"Domain: {domain}")
        self.log_info(f"Input tables: {input_tables}")

        return self.current_job_id

    def _create_directory_structure(self):
        """Job ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        dirs = [
            self.current_job_dir / "phase1_discovery",
            self.current_job_dir / "phase2_refinement",
            self.current_job_dir / "phase3_governance",
            self.current_job_dir / "llm_calls",
            self.current_job_dir / "artifacts",
        ]
        for d in dirs:
            d.mkdir(parents=True, exist_ok=True)

    def _setup_file_logger(self):
        """íŒŒì¼ ë¡œê±° ì„¤ì •"""
        log_file = self.current_job_dir / "pipeline.log"

        self._file_logger = logging.getLogger(f"job.{self.current_job_id}")
        self._file_logger.setLevel(logging.DEBUG)
        self._file_logger.handlers = []

        file_handler = logging.FileHandler(log_file, encoding="utf-8")
        file_handler.setFormatter(logging.Formatter(
            "%(asctime)s | %(levelname)-8s | %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S"
        ))
        self._file_logger.addHandler(file_handler)

    def _save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        if self.current_job_dir and self.metadata:
            metadata_file = self.current_job_dir / "job_metadata.json"
            with open(metadata_file, "w", encoding="utf-8") as f:
                json.dump(asdict(self.metadata), f, indent=2, ensure_ascii=False, default=str)

    def end_job(self, status: str = "completed") -> Dict[str, Any]:
        """
        Job ì¢…ë£Œ

        Returns:
            Job ìš”ì•½ ì •ë³´
        """
        if not self.current_job_id:
            return {}

        self.log_info(f"Job ending: {self.current_job_id}")

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if self.metadata:
            self.metadata.completed_at = datetime.now().isoformat()
            self.metadata.status = status
            self._save_metadata()

        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary()
        summary_file = self.current_job_dir / "summary.json"
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)

        self.log_info(f"Job completed: {status}")
        self.log_info(f"Total LLM calls: {self.metadata.total_llm_calls if self.metadata else 0}")
        self.log_info(f"Total tokens: {self.metadata.total_tokens if self.metadata else 0}")

        # ë¦¬ì…‹
        result = {
            "job_id": self.current_job_id,
            "job_dir": str(self.current_job_dir),
            "summary": summary,
        }

        self.current_job_id = None
        self.current_job_dir = None
        self.metadata = None
        self._agent_records = {}
        self._llm_call_counter = 0

        return result

    def _generate_summary(self) -> Dict[str, Any]:
        """Job ìš”ì•½ ìƒì„±"""
        if not self.metadata:
            return {}

        # ì—ì´ì „íŠ¸ë³„ í†µê³„
        agent_stats = {}
        for agent_name, record in self._agent_records.items():
            agent_stats[agent_name] = {
                "phase": record.phase,
                "success": record.success,
                "duration_ms": record.duration_ms,
                "llm_calls": len(record.llm_calls),
            }

        return {
            "job_id": self.metadata.job_id,
            "domain": self.metadata.domain,
            "started_at": self.metadata.started_at,
            "completed_at": self.metadata.completed_at,
            "duration_seconds": self._calculate_duration(),
            "status": self.metadata.status,
            "statistics": {
                "total_agents": self.metadata.total_agents,
                "completed_agents": self.metadata.completed_agents,
                "total_llm_calls": self.metadata.total_llm_calls,
                "total_tokens": self.metadata.total_tokens,
            },
            "agent_stats": agent_stats,
            "input_tables": self.metadata.input_tables,
        }

    def _calculate_duration(self) -> float:
        """ì‹¤í–‰ ì‹œê°„ ê³„ì‚° (ì´ˆ)"""
        if not self.metadata or not self.metadata.completed_at:
            return 0.0

        start = datetime.fromisoformat(self.metadata.started_at)
        end = datetime.fromisoformat(self.metadata.completed_at)
        return (end - start).total_seconds()

    # === ë¡œê¹… ë©”ì„œë“œ ===

    def log(self, level: LogLevel, message: str, **kwargs):
        """ë²”ìš© ë¡œê·¸"""
        if self._file_logger:
            extra = f" | {kwargs}" if kwargs else ""
            getattr(self._file_logger, level.lower())(f"{message}{extra}")

    def log_debug(self, message: str, **kwargs):
        self.log(LogLevel.DEBUG, message, **kwargs)

    def log_info(self, message: str, **kwargs):
        self.log(LogLevel.INFO, message, **kwargs)

    def log_warning(self, message: str, **kwargs):
        self.log(LogLevel.WARNING, message, **kwargs)

    def log_error(self, message: str, **kwargs):
        self.log(LogLevel.ERROR, message, **kwargs)

    # === ì—ì´ì „íŠ¸ ì‹¤í–‰ ê¸°ë¡ ===

    def start_agent_execution(
        self,
        agent_name: str,
        agent_type: str,
        phase: PhaseType,
        todo_id: Optional[str] = None,
        input_data: Optional[Dict[str, Any]] = None,
    ) -> str:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ ê¸°ë¡"""
        record = AgentExecutionRecord(
            agent_name=agent_name,
            agent_type=agent_type,
            phase=phase.value,
            started_at=datetime.now().isoformat(),
            todo_id=todo_id,
            input_data=input_data or {},
        )

        self._agent_records[agent_name] = record

        if self.metadata:
            self.metadata.total_agents += 1
            self._save_metadata()

        self.log_info(f"Agent started: {agent_name} ({agent_type})", phase=phase.value)

        return agent_name

    def end_agent_execution(
        self,
        agent_name: str,
        output_data: Optional[Dict[str, Any]] = None,
        success: bool = True,
        error: Optional[str] = None,
    ):
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¢…ë£Œ ê¸°ë¡"""
        if agent_name not in self._agent_records:
            return

        record = self._agent_records[agent_name]
        record.completed_at = datetime.now().isoformat()
        record.output_data = output_data or {}
        record.success = success
        record.error = error

        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        start = datetime.fromisoformat(record.started_at)
        end = datetime.fromisoformat(record.completed_at)
        record.duration_ms = (end - start).total_seconds() * 1000

        # íŒŒì¼ë¡œ ì €ì¥
        self._save_agent_record(record)

        if self.metadata:
            self.metadata.completed_agents += 1
            self._save_metadata()

        status = "SUCCESS" if success else f"FAILED: {error}"
        self.log_info(
            f"Agent completed: {agent_name}",
            status=status,
            duration_ms=record.duration_ms
        )

    def _save_agent_record(self, record: AgentExecutionRecord):
        """ì—ì´ì „íŠ¸ ê¸°ë¡ íŒŒì¼ë¡œ ì €ì¥"""
        if not self.current_job_dir:
            return

        phase_dir = self.current_job_dir / record.phase
        agent_file = phase_dir / f"{record.agent_type}.json"

        with open(agent_file, "w", encoding="utf-8") as f:
            json.dump(asdict(record), f, indent=2, ensure_ascii=False, default=str)

    def add_agent_log(self, agent_name: str, message: str, level: LogLevel = LogLevel.INFO):
        """ì—ì´ì „íŠ¸ ë‚´ë¶€ ë¡œê·¸ ì¶”ê°€"""
        if agent_name in self._agent_records:
            self._agent_records[agent_name].logs.append({
                "timestamp": datetime.now().isoformat(),
                "level": level.value,
                "message": message,
            })

        self.log(level, f"[{agent_name}] {message}")

    # === v5.1: ì‚¬ê³  ê³¼ì • ê¸°ë¡ ===

    def log_thinking(
        self,
        agent_name: str,
        thinking_type: ThinkingType,
        content: str,
        context: Optional[Dict[str, Any]] = None,
        confidence: Optional[float] = None,
        evidence: Optional[List[str]] = None,
        related_data: Optional[Dict[str, Any]] = None,
    ):
        """
        ì—ì´ì „íŠ¸ì˜ ì‚¬ê³  ê³¼ì • ê¸°ë¡

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            thinking_type: ì‚¬ê³  ìœ í˜• (analysis, reasoning, decision ë“±)
            content: ì‚¬ê³  ë‚´ìš©
            context: ì‚¬ê³  ì»¨í…ìŠ¤íŠ¸
            confidence: í™•ì‹ ë„ (0.0-1.0)
            evidence: ê·¼ê±° ëª©ë¡
            related_data: ê´€ë ¨ ë°ì´í„°
        """
        if agent_name not in self._agent_records:
            return

        thinking_record = ThinkingRecord(
            timestamp=datetime.now().isoformat(),
            thinking_type=thinking_type.value,
            content=content,
            context=context or {},
            confidence=confidence,
            evidence=evidence or [],
            related_data=related_data or {},
        )

        self._agent_records[agent_name].thinking_process.append(thinking_record)

        # íŒŒì¼ì—ë„ ê¸°ë¡
        self._save_thinking_to_file(agent_name, thinking_record)

        # ë¡œê·¸ ì¶œë ¥
        conf_str = f" (confidence: {confidence:.2f})" if confidence else ""
        self.log_info(f"[{agent_name}] ğŸ’­ {thinking_type.value}: {content[:200]}...{conf_str}")

    def _save_thinking_to_file(self, agent_name: str, record: ThinkingRecord):
        """ì‚¬ê³  ê³¼ì •ì„ ë³„ë„ íŒŒì¼ì— ì €ì¥"""
        if not self.current_job_dir:
            return

        thinking_dir = self.current_job_dir / "thinking"
        thinking_dir.mkdir(exist_ok=True)

        thinking_file = thinking_dir / f"{agent_name}_thinking.jsonl"
        with open(thinking_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(asdict(record), ensure_ascii=False, default=str) + "\n")

    def log_analysis(
        self,
        agent_name: str,
        analysis_target: str,
        findings: List[str],
        methodology: Optional[str] = None,
        data_examined: Optional[Dict[str, Any]] = None,
        confidence: Optional[float] = None,
    ):
        """
        ë°ì´í„° ë¶„ì„ ê³¼ì • ê¸°ë¡

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            analysis_target: ë¶„ì„ ëŒ€ìƒ
            findings: ë°œê²¬ ì‚¬í•­ ëª©ë¡
            methodology: ë¶„ì„ ë°©ë²•ë¡ 
            data_examined: ë¶„ì„í•œ ë°ì´í„°
            confidence: ë¶„ì„ í™•ì‹ ë„
        """
        content = f"Analyzing '{analysis_target}': {', '.join(findings[:3])}"
        if len(findings) > 3:
            content += f" (+{len(findings)-3} more findings)"

        self.log_thinking(
            agent_name=agent_name,
            thinking_type=ThinkingType.ANALYSIS,
            content=content,
            context={
                "target": analysis_target,
                "methodology": methodology,
            },
            confidence=confidence,
            evidence=findings,
            related_data=data_examined or {},
        )

    def log_reasoning(
        self,
        agent_name: str,
        premise: str,
        logic: str,
        conclusion: str,
        confidence: Optional[float] = None,
        supporting_evidence: Optional[List[str]] = None,
    ):
        """
        ì¶”ë¡  ê³¼ì • ê¸°ë¡

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            premise: ì „ì œ
            logic: ë…¼ë¦¬ì  ì¶”ë¡ 
            conclusion: ê²°ë¡ 
            confidence: ì¶”ë¡  í™•ì‹ ë„
            supporting_evidence: ì§€ì§€ ê·¼ê±°
        """
        content = f"Premise: {premise} â†’ Logic: {logic} â†’ Conclusion: {conclusion}"

        self.log_thinking(
            agent_name=agent_name,
            thinking_type=ThinkingType.REASONING,
            content=content,
            context={
                "premise": premise,
                "logic": logic,
                "conclusion": conclusion,
            },
            confidence=confidence,
            evidence=supporting_evidence or [],
        )

    def log_hypothesis(
        self,
        agent_name: str,
        hypothesis: str,
        basis: List[str],
        testable: bool = True,
        confidence: Optional[float] = None,
    ):
        """
        ê°€ì„¤ ìˆ˜ë¦½ ê¸°ë¡

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            hypothesis: ê°€ì„¤ ë‚´ìš©
            basis: ê°€ì„¤ì˜ ê·¼ê±°
            testable: ê²€ì¦ ê°€ëŠ¥ ì—¬ë¶€
            confidence: ê°€ì„¤ í™•ì‹ ë„
        """
        content = f"Hypothesis: {hypothesis} (testable: {testable})"

        self.log_thinking(
            agent_name=agent_name,
            thinking_type=ThinkingType.HYPOTHESIS,
            content=content,
            context={
                "testable": testable,
            },
            confidence=confidence,
            evidence=basis,
        )

    def log_decision(
        self,
        agent_name: str,
        decision: str,
        options_considered: List[str],
        rationale: str,
        confidence: Optional[float] = None,
        impact: Optional[str] = None,
    ):
        """
        ì˜ì‚¬ê²°ì • ê¸°ë¡

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            decision: ê²°ì • ë‚´ìš©
            options_considered: ê³ ë ¤í•œ ì˜µì…˜ë“¤
            rationale: ê²°ì • ì´ìœ 
            confidence: ê²°ì • í™•ì‹ ë„
            impact: ì˜ˆìƒ ì˜í–¥
        """
        content = f"Decision: {decision} | Rationale: {rationale}"

        # ì£¼ìš” ê²°ì •ìœ¼ë¡œë„ ê¸°ë¡
        if agent_name in self._agent_records:
            self._agent_records[agent_name].key_decisions.append({
                "timestamp": datetime.now().isoformat(),
                "decision": decision,
                "options": options_considered,
                "rationale": rationale,
                "confidence": confidence,
                "impact": impact,
            })

        self.log_thinking(
            agent_name=agent_name,
            thinking_type=ThinkingType.DECISION,
            content=content,
            context={
                "options_considered": options_considered,
                "rationale": rationale,
                "impact": impact,
            },
            confidence=confidence,
        )

    def log_insight(
        self,
        agent_name: str,
        insight: str,
        source: str,
        importance: str = "medium",
        actionable: bool = True,
        confidence: Optional[float] = None,
    ):
        """
        ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ê¸°ë¡

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            insight: ì¸ì‚¬ì´íŠ¸ ë‚´ìš©
            source: ì¸ì‚¬ì´íŠ¸ ì¶œì²˜
            importance: ì¤‘ìš”ë„ (low, medium, high, critical)
            actionable: ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€
            confidence: ì¸ì‚¬ì´íŠ¸ í™•ì‹ ë„
        """
        content = f"ğŸ’¡ Insight [{importance}]: {insight} (from: {source})"

        self.log_thinking(
            agent_name=agent_name,
            thinking_type=ThinkingType.INSIGHT,
            content=content,
            context={
                "source": source,
                "importance": importance,
                "actionable": actionable,
            },
            confidence=confidence,
        )

    def log_evaluation(
        self,
        agent_name: str,
        subject: str,
        criteria: List[str],
        scores: Dict[str, float],
        overall_score: float,
        verdict: str,
    ):
        """
        í‰ê°€ ê³¼ì • ê¸°ë¡

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            subject: í‰ê°€ ëŒ€ìƒ
            criteria: í‰ê°€ ê¸°ì¤€
            scores: ê¸°ì¤€ë³„ ì ìˆ˜
            overall_score: ì¢…í•© ì ìˆ˜
            verdict: í‰ê°€ ê²°ë¡ 
        """
        content = f"Evaluating '{subject}': Overall {overall_score:.2f} â†’ {verdict}"

        self.log_thinking(
            agent_name=agent_name,
            thinking_type=ThinkingType.EVALUATION,
            content=content,
            context={
                "subject": subject,
                "criteria": criteria,
                "scores": scores,
                "verdict": verdict,
            },
            confidence=overall_score,
        )

    # === v5.1: ì¶”ë¡  ì²´ì¸ ê¸°ë¡ ===

    _reasoning_chains: Dict[str, ReasoningChain] = {}

    def start_reasoning_chain(
        self,
        agent_name: str,
        goal: str,
    ) -> str:
        """
        ì¶”ë¡  ì²´ì¸ ì‹œì‘

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            goal: ì¶”ë¡  ëª©í‘œ

        Returns:
            chain_id
        """
        chain_id = f"chain_{datetime.now().strftime('%H%M%S')}_{len(self._reasoning_chains)}"

        chain = ReasoningChain(
            chain_id=chain_id,
            agent_name=agent_name,
            started_at=datetime.now().isoformat(),
            goal=goal,
        )

        self._reasoning_chains[chain_id] = chain

        if agent_name in self._agent_records:
            self._agent_records[agent_name].reasoning_chains.append(chain_id)

        self.log_info(f"[{agent_name}] ğŸ”— Reasoning chain started: {goal}")

        return chain_id

    def add_reasoning_step(
        self,
        chain_id: str,
        thinking_type: ThinkingType,
        content: str,
        confidence: Optional[float] = None,
        evidence: Optional[List[str]] = None,
    ):
        """ì¶”ë¡  ì²´ì¸ì— ë‹¨ê³„ ì¶”ê°€"""
        if chain_id not in self._reasoning_chains:
            return

        step = ThinkingRecord(
            timestamp=datetime.now().isoformat(),
            thinking_type=thinking_type.value,
            content=content,
            confidence=confidence,
            evidence=evidence or [],
        )

        self._reasoning_chains[chain_id].steps.append(step)

    def end_reasoning_chain(
        self,
        chain_id: str,
        conclusion: str,
        confidence: Optional[float] = None,
        success: bool = True,
    ):
        """ì¶”ë¡  ì²´ì¸ ì¢…ë£Œ"""
        if chain_id not in self._reasoning_chains:
            return

        chain = self._reasoning_chains[chain_id]
        chain.completed_at = datetime.now().isoformat()
        chain.final_conclusion = conclusion
        chain.confidence = confidence
        chain.success = success

        # íŒŒì¼ì— ì €ì¥
        self._save_reasoning_chain(chain)

        self.log_info(
            f"[{chain.agent_name}] ğŸ”— Reasoning chain completed: {conclusion[:100]}",
            confidence=confidence,
            steps=len(chain.steps)
        )

    def _save_reasoning_chain(self, chain: ReasoningChain):
        """ì¶”ë¡  ì²´ì¸ì„ íŒŒì¼ì— ì €ì¥"""
        if not self.current_job_dir:
            return

        chains_dir = self.current_job_dir / "reasoning_chains"
        chains_dir.mkdir(exist_ok=True)

        chain_file = chains_dir / f"{chain.chain_id}.json"
        with open(chain_file, "w", encoding="utf-8") as f:
            json.dump(asdict(chain), f, indent=2, ensure_ascii=False, default=str)

    def set_analysis_summary(self, agent_name: str, summary: str):
        """ì—ì´ì „íŠ¸ì˜ ë¶„ì„ ìš”ì•½ ì„¤ì •"""
        if agent_name in self._agent_records:
            self._agent_records[agent_name].analysis_summary = summary
            self.log_info(f"[{agent_name}] ğŸ“ Analysis summary: {summary[:200]}...")

    # === LLM í˜¸ì¶œ ê¸°ë¡ ===

    def log_llm_call(
        self,
        agent_name: str,
        model: str,
        messages: List[Dict[str, str]],
        response: str,
        prompt_tokens: int = 0,
        completion_tokens: int = 0,
        latency_ms: float = 0,
        success: bool = True,
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
        # v5.1: ì‚¬ê³  ê³¼ì • ê´€ë ¨ íŒŒë¼ë¯¸í„°
        purpose: Optional[str] = None,
        thinking_before: Optional[str] = None,
        thinking_after: Optional[str] = None,
        extracted_insights: Optional[List[str]] = None,
    ) -> str:
        """
        LLM í˜¸ì¶œ ê¸°ë¡ (v5.1 - ì‚¬ê³  ê³¼ì • í¬í•¨)

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            model: ì‚¬ìš©ëœ ëª¨ë¸
            messages: ëŒ€í™” ë©”ì‹œì§€
            response: LLM ì‘ë‹µ
            prompt_tokens: í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜
            completion_tokens: ì™„ë£Œ í† í° ìˆ˜
            latency_ms: ì§€ì—° ì‹œê°„ (ms)
            success: ì„±ê³µ ì—¬ë¶€
            error: ì—ëŸ¬ ë©”ì‹œì§€
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            purpose: LLM í˜¸ì¶œ ëª©ì 
            thinking_before: í˜¸ì¶œ ì „ ì—ì´ì „íŠ¸ì˜ ìƒê°
            thinking_after: í˜¸ì¶œ í›„ ì—ì´ì „íŠ¸ì˜ í•´ì„
            extracted_insights: ì‘ë‹µì—ì„œ ì¶”ì¶œëœ ì¸ì‚¬ì´íŠ¸
        """
        self._llm_call_counter += 1
        call_id = f"llm_{self._llm_call_counter:06d}"

        record = LLMCallRecord(
            timestamp=datetime.now().isoformat(),
            agent_name=agent_name,
            model=model,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=prompt_tokens + completion_tokens,
            latency_ms=latency_ms,
            messages=messages,
            response=response[:10000] if response else "",  # ì‘ë‹µ ê¸¸ì´ ì œí•œ
            success=success,
            error=error,
            metadata=metadata or {},
            # v5.1: ì‚¬ê³  ê³¼ì •
            purpose=purpose,
            thinking_before=thinking_before,
            thinking_after=thinking_after,
            extracted_insights=extracted_insights or [],
        )

        # JSONL íŒŒì¼ì— ì¶”ê°€
        if self._llm_file:
            with open(self._llm_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(record), ensure_ascii=False, default=str) + "\n")

        # ì—ì´ì „íŠ¸ ë ˆì½”ë“œì— call ID ì¶”ê°€
        if agent_name in self._agent_records:
            self._agent_records[agent_name].llm_calls.append(call_id)

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if self.metadata:
            self.metadata.total_llm_calls += 1
            self.metadata.total_tokens += record.total_tokens

        # ì‚¬ê³  ê³¼ì •ì´ ìˆìœ¼ë©´ ìƒì„¸ ë¡œê·¸
        if purpose or thinking_before or thinking_after:
            self.log_debug(
                f"LLM call: {call_id}",
                agent=agent_name,
                model=model,
                tokens=record.total_tokens,
                latency_ms=latency_ms,
                purpose=purpose,
            )
        else:
            self.log_debug(
                f"LLM call: {call_id}",
                agent=agent_name,
                model=model,
                tokens=record.total_tokens,
                latency_ms=latency_ms
            )

        return call_id

    # === ì‚°ì¶œë¬¼ ì €ì¥ ===

    def save_artifact(
        self,
        name: str,
        data: Any,
        artifact_type: str = "json",
    ):
        """ì‚°ì¶œë¬¼ ì €ì¥"""
        if not self.current_job_dir:
            return

        artifacts_dir = self.current_job_dir / "artifacts"

        if artifact_type == "json":
            file_path = artifacts_dir / f"{name}.json"
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False, default=str)
        else:
            file_path = artifacts_dir / f"{name}.txt"
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(str(data))

        self.log_info(f"Artifact saved: {name}", path=str(file_path))

    def save_ontology(self, ontology: Dict[str, Any]):
        """ì˜¨í†¨ë¡œì§€ ì €ì¥"""
        self.save_artifact("ontology", ontology)

    def save_insights(self, insights: List[Dict[str, Any]]):
        """ì¸ì‚¬ì´íŠ¸ ì €ì¥"""
        self.save_artifact("insights", insights)

    def save_governance_decisions(self, decisions: List[Dict[str, Any]]):
        """ê±°ë²„ë„ŒìŠ¤ ê²°ì • ì €ì¥"""
        self.save_artifact("governance_decisions", decisions)

    def save_knowledge_graph(self, kg: Dict[str, Any]):
        """Knowledge Graph ì €ì¥"""
        self.save_artifact("knowledge_graph", kg)

    def save_palantir_insights(self, insights: List[Dict[str, Any]]):
        """v10.0: íŒ”ë€í‹°ì–´ ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ì¸ì‚¬ì´íŠ¸ ì €ì¥"""
        self.save_artifact("predictive_insights", insights)

    # === ìœ í‹¸ë¦¬í‹° ===

    def get_job_dir(self) -> Optional[Path]:
        """í˜„ì¬ Job ë””ë ‰í† ë¦¬ ë°˜í™˜"""
        return self.current_job_dir

    def get_job_id(self) -> Optional[str]:
        """í˜„ì¬ Job ID ë°˜í™˜"""
        return self.current_job_id

    def is_active(self) -> bool:
        """Jobì´ í™œì„±í™” ìƒíƒœì¸ì§€ í™•ì¸"""
        return self.current_job_id is not None

    def list_jobs(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  Job ëª©ë¡ ë°˜í™˜"""
        jobs = []
        for job_dir in sorted(self.base_dir.iterdir(), reverse=True):
            if job_dir.is_dir():
                metadata_file = job_dir / "job_metadata.json"
                if metadata_file.exists():
                    with open(metadata_file, "r", encoding="utf-8") as f:
                        jobs.append(json.load(f))
        return jobs


# === ì „ì—­ í•¨ìˆ˜ ===

def get_job_logger() -> JobLogger:
    """JobLogger ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return JobLogger.get_instance()


def start_job(domain: str, input_tables: List[str], config: Optional[Dict[str, Any]] = None) -> str:
    """Job ì‹œì‘ (í¸ì˜ í•¨ìˆ˜)"""
    return get_job_logger().start_job(domain, input_tables, config)


def end_job(status: str = "completed") -> Dict[str, Any]:
    """Job ì¢…ë£Œ (í¸ì˜ í•¨ìˆ˜)"""
    return get_job_logger().end_job(status)
