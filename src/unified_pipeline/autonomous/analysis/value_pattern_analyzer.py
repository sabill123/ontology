"""
Value Pattern Analyzer (v1.0)

ë„ë©”ì¸ ë¬´ê´€ ë²”ìš© ê°’ íŒ¨í„´ ë¶„ì„ê¸°
- í•˜ë“œì½”ë”©ëœ ë„ë©”ì¸ ì§€ì‹ ì—†ìŒ
- ìˆœìˆ˜ í†µê³„ì /íŒ¨í„´ ë¶„ì„ë§Œ ìˆ˜í–‰
- LLMì´ ê²°ê³¼ë¥¼ í•´ì„í•˜ì—¬ ì˜ë¯¸ ë¶€ì—¬

í•µì‹¬ ì›ë¦¬:
1. ê°’ì˜ í˜•íƒœì  íŠ¹ì„±ë§Œ ì¶”ì¶œ (ê¸¸ì´, ë¬¸ìíƒ€ì…, êµ¬ì¡°)
2. ê°™ì€ í…Œì´ë¸” ë‚´ 1:1 ë§¤í•‘ ì»¬ëŸ¼ íƒì§€ (Bridge Table í›„ë³´)
3. ë‹¤ë¥¸ í…Œì´ë¸” ê°„ íŒ¨í„´ ìœ ì‚¬ì„± ë¶„ì„
4. LLMì—ê²Œ ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
"""

import re
import logging
from typing import Dict, List, Any, Set, Tuple, Optional
from dataclasses import dataclass, field
from collections import Counter, defaultdict

logger = logging.getLogger(__name__)


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class ValuePattern:
    """ë‹¨ì¼ ì»¬ëŸ¼ì˜ ê°’ íŒ¨í„´ ë¶„ì„ ê²°ê³¼"""
    table: str
    column: str

    # ê¸°ë³¸ í†µê³„
    total_count: int
    unique_count: int
    null_count: int
    unique_ratio: float

    # íŒ¨í„´ ë¶„í¬ (ë„ë©”ì¸ ë¬´ê´€)
    length_distribution: Dict[int, int]  # {ê¸¸ì´: ê°œìˆ˜}
    dominant_length: int
    length_consistency: float  # 0-1, 1ì´ë©´ ëª¨ë“  ê°’ì´ ê°™ì€ ê¸¸ì´

    # ë¬¸ì íƒ€ì… ë¶„í¬
    char_type_distribution: Dict[str, int]  # {"UPPER": n, "LOWER": n, ...}
    dominant_char_type: str

    # êµ¬ì¡° íŒ¨í„´
    structure_patterns: Dict[str, int]  # {"AAA": n, "AA9": n, "A9A9": n, ...}
    dominant_structure: str

    # ìƒ˜í”Œ
    sample_values: List[str] = field(default_factory=list)

    # ë©”íƒ€
    is_likely_code: bool = False  # ì§§ê³  ì¼ê´€ëœ íŒ¨í„´ = ì½”ë“œì„± ë°ì´í„°
    is_likely_identifier: bool = False  # unique ratio ë†’ê³  íŒ¨í„´ ì¼ê´€

    def to_dict(self) -> Dict[str, Any]:
        return {
            "table": self.table,
            "column": self.column,
            "total_count": self.total_count,
            "unique_count": self.unique_count,
            "unique_ratio": round(self.unique_ratio, 4),
            "dominant_length": self.dominant_length,
            "length_consistency": round(self.length_consistency, 4),
            "dominant_char_type": self.dominant_char_type,
            "dominant_structure": self.dominant_structure,
            "sample_values": self.sample_values[:10],
            "is_likely_code": self.is_likely_code,
            "is_likely_identifier": self.is_likely_identifier,
        }


@dataclass
class SameTableMapping:
    """ê°™ì€ í…Œì´ë¸” ë‚´ 1:1 ë§¤í•‘ ì»¬ëŸ¼ ìŒ (Bridge Table í›„ë³´)"""
    table: str
    column_a: str
    column_b: str

    # íŒ¨í„´ ì •ë³´
    pattern_a: str  # "2_UPPER"
    pattern_b: str  # "3_UPPER"

    # ë§¤í•‘ ì •ë³´
    mapping_count: int  # ë§¤í•‘ëœ ìŒì˜ ìˆ˜
    is_bijective: bool  # ì–‘ë°©í–¥ 1:1ì¸ì§€

    # ìƒ˜í”Œ ë§¤í•‘
    sample_mappings: List[Tuple[str, str]] = field(default_factory=list)

    # ì‹ ë¢°ë„
    confidence: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "table": self.table,
            "column_a": self.column_a,
            "column_b": self.column_b,
            "pattern_a": self.pattern_a,
            "pattern_b": self.pattern_b,
            "mapping_count": self.mapping_count,
            "is_bijective": self.is_bijective,
            "sample_mappings": self.sample_mappings[:10],
            "confidence": round(self.confidence, 4),
        }


@dataclass
class CrossTablePatternMatch:
    """ë‹¤ë¥¸ í…Œì´ë¸” ê°„ ê°™ì€ íŒ¨í„´ì„ ê°€ì§„ ì»¬ëŸ¼ ìŒ"""
    table_a: str
    column_a: str
    table_b: str
    column_b: str

    # íŒ¨í„´ ìœ ì‚¬ë„
    pattern_match: str  # ê³µí†µ íŒ¨í„´ (ì˜ˆ: "2_UPPER")
    length_match: bool
    char_type_match: bool
    structure_match: bool

    # ê°’ ê²¹ì¹¨ (ì§ì ‘ ë§¤ì¹­ ì—¬ë¶€)
    has_value_overlap: bool
    overlap_ratio: float

    def to_dict(self) -> Dict[str, Any]:
        return {
            "table_a": self.table_a,
            "column_a": self.column_a,
            "table_b": self.table_b,
            "column_b": self.column_b,
            "pattern_match": self.pattern_match,
            "length_match": self.length_match,
            "char_type_match": self.char_type_match,
            "structure_match": self.structure_match,
            "has_value_overlap": self.has_value_overlap,
            "overlap_ratio": round(self.overlap_ratio, 4),
        }


# =============================================================================
# Value Pattern Analyzer
# =============================================================================

class ValuePatternAnalyzer:
    """
    ë²”ìš© ê°’ íŒ¨í„´ ë¶„ì„ê¸°

    ë„ë©”ì¸ ì§€ì‹ ì—†ì´ ìˆœìˆ˜ í†µê³„/íŒ¨í„´ ë¶„ì„ë§Œ ìˆ˜í–‰
    LLMì´ ê²°ê³¼ë¥¼ í•´ì„í•˜ì—¬ ì˜ë¯¸ ë¶€ì—¬
    """

    def analyze_all_columns(
        self,
        tables_data: Dict[str, Dict[str, List[Any]]]
    ) -> Dict[str, ValuePattern]:
        """ëª¨ë“  í…Œì´ë¸”ì˜ ëª¨ë“  ì»¬ëŸ¼ íŒ¨í„´ ë¶„ì„"""
        patterns = {}

        for table_name, columns_data in tables_data.items():
            for column_name, values in columns_data.items():
                key = f"{table_name}.{column_name}"
                patterns[key] = self.analyze_column(table_name, column_name, values)

        return patterns

    def analyze_column(
        self,
        table: str,
        column: str,
        values: List[Any]
    ) -> ValuePattern:
        """ë‹¨ì¼ ì»¬ëŸ¼ íŒ¨í„´ ë¶„ì„"""
        # None ì œê±° ë° ë¬¸ìì—´ ë³€í™˜
        str_values = [str(v).strip() for v in values if v is not None and str(v).strip()]

        total_count = len(values)
        null_count = len(values) - len(str_values)
        unique_values = set(str_values)
        unique_count = len(unique_values)
        unique_ratio = unique_count / len(str_values) if str_values else 0

        # ê¸¸ì´ ë¶„í¬
        length_dist = Counter(len(v) for v in str_values)
        dominant_length = length_dist.most_common(1)[0][0] if length_dist else 0
        length_consistency = length_dist[dominant_length] / len(str_values) if str_values else 0

        # ë¬¸ì íƒ€ì… ë¶„í¬
        char_types = Counter(self._classify_char_type(v) for v in str_values)
        dominant_char_type = char_types.most_common(1)[0][0] if char_types else "UNKNOWN"

        # êµ¬ì¡° íŒ¨í„´ ë¶„í¬
        structures = Counter(self._extract_structure(v) for v in str_values)
        dominant_structure = structures.most_common(1)[0][0] if structures else "UNKNOWN"

        # ì½”ë“œì„± ë°ì´í„° íŒë‹¨ (ì§§ê³  ì¼ê´€ëœ íŒ¨í„´)
        is_likely_code = (
            dominant_length <= 10 and
            length_consistency >= 0.8 and
            dominant_char_type in ("UPPER", "ALNUM_UPPER", "NUMERIC")
        )

        # ì‹ë³„ì íŒë‹¨ (uniqueí•˜ê³  íŒ¨í„´ ì¼ê´€)
        is_likely_identifier = (
            unique_ratio >= 0.9 and
            length_consistency >= 0.7
        )

        return ValuePattern(
            table=table,
            column=column,
            total_count=total_count,
            unique_count=unique_count,
            null_count=null_count,
            unique_ratio=unique_ratio,
            length_distribution=dict(length_dist),
            dominant_length=dominant_length,
            length_consistency=length_consistency,
            char_type_distribution=dict(char_types),
            dominant_char_type=dominant_char_type,
            structure_patterns=dict(structures.most_common(10)),
            dominant_structure=dominant_structure,
            sample_values=list(unique_values)[:20],
            is_likely_code=is_likely_code,
            is_likely_identifier=is_likely_identifier,
        )

    def _classify_char_type(self, value: str) -> str:
        """ë¬¸ì íƒ€ì… ë¶„ë¥˜ (ë„ë©”ì¸ ë¬´ê´€)"""
        if not value:
            return "EMPTY"

        if value.isdigit():
            return "NUMERIC"
        elif value.isalpha():
            if value.isupper():
                return "UPPER"
            elif value.islower():
                return "LOWER"
            else:
                return "MIXED_CASE"
        elif value.isalnum():
            if value[0].isalpha():
                if all(c.isupper() or c.isdigit() for c in value):
                    return "ALNUM_UPPER"
                elif all(c.islower() or c.isdigit() for c in value):
                    return "ALNUM_LOWER"
                return "ALNUM_MIXED"
            else:
                return "NUM_ALPHA"
        else:
            # íŠ¹ìˆ˜ë¬¸ì í¬í•¨
            if '-' in value or '_' in value:
                return "WITH_SEPARATOR"
            elif ' ' in value:
                return "WITH_SPACE"
            else:
                return "SPECIAL"

    def _extract_structure(self, value: str) -> str:
        """
        ê°’ì˜ êµ¬ì¡° íŒ¨í„´ ì¶”ì¶œ (ë„ë©”ì¸ ë¬´ê´€)

        ì˜ˆ:
        - "KE" â†’ "AA"
        - "KE123" â†’ "AA999"
        - "2024-01-15" â†’ "9999-99-99"
        - "AB-123-XY" â†’ "AA-999-AA"
        """
        if not value:
            return "EMPTY"

        pattern = []
        for char in value:
            if char.isupper():
                pattern.append('A')
            elif char.islower():
                pattern.append('a')
            elif char.isdigit():
                pattern.append('9')
            else:
                pattern.append(char)  # êµ¬ë¶„ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€

        # ì—°ì†ëœ ê°™ì€ íŒ¨í„´ ì••ì¶• (ì„ íƒì )
        # "AAAA" â†’ "A+" í˜•íƒœë¡œ ì••ì¶•í•˜ì§€ ì•ŠìŒ - ê¸¸ì´ ì •ë³´ ìœ ì§€ê°€ ë” ìœ ìš©
        return ''.join(pattern)


# =============================================================================
# Same-Table Mapping Detector (Bridge Table í›„ë³´)
# =============================================================================

class SameTableMappingDetector:
    """
    ê°™ì€ í…Œì´ë¸” ë‚´ 1:1 ë§¤í•‘ ì»¬ëŸ¼ íƒì§€

    Bridge Table(ë§¤í•‘ í…Œì´ë¸”) í›„ë³´ ë°œê²¬
    ì˜ˆ: airlines í…Œì´ë¸”ì˜ iata_code â†” icao_code
    """

    def __init__(self, pattern_analyzer: ValuePatternAnalyzer):
        self.pattern_analyzer = pattern_analyzer

    def detect_mappings(
        self,
        tables_data: Dict[str, Dict[str, List[Any]]],
        patterns: Dict[str, ValuePattern]
    ) -> List[SameTableMapping]:
        """ëª¨ë“  í…Œì´ë¸”ì—ì„œ 1:1 ë§¤í•‘ ì»¬ëŸ¼ ìŒ íƒì§€"""
        mappings = []

        for table_name, columns_data in tables_data.items():
            table_mappings = self._detect_in_table(table_name, columns_data, patterns)
            mappings.extend(table_mappings)

        return mappings

    def _detect_in_table(
        self,
        table_name: str,
        columns_data: Dict[str, List[Any]],
        patterns: Dict[str, ValuePattern]
    ) -> List[SameTableMapping]:
        """ë‹¨ì¼ í…Œì´ë¸” ë‚´ ë§¤í•‘ íƒì§€"""
        mappings = []
        column_names = list(columns_data.keys())

        for i, col_a in enumerate(column_names):
            pattern_a = patterns.get(f"{table_name}.{col_a}")
            if not pattern_a:
                continue

            # ì½”ë“œì„± ë°ì´í„°ë§Œ ëŒ€ìƒ
            if not pattern_a.is_likely_code and not pattern_a.is_likely_identifier:
                continue

            for col_b in column_names[i+1:]:
                pattern_b = patterns.get(f"{table_name}.{col_b}")
                if not pattern_b:
                    continue

                if not pattern_b.is_likely_code and not pattern_b.is_likely_identifier:
                    continue

                # 1:1 ë§¤í•‘ í™•ì¸
                mapping_result = self._check_bijective_mapping(
                    columns_data[col_a],
                    columns_data[col_b]
                )

                if mapping_result["is_mapping"]:
                    mappings.append(SameTableMapping(
                        table=table_name,
                        column_a=col_a,
                        column_b=col_b,
                        pattern_a=f"{pattern_a.dominant_length}_{pattern_a.dominant_char_type}",
                        pattern_b=f"{pattern_b.dominant_length}_{pattern_b.dominant_char_type}",
                        mapping_count=mapping_result["mapping_count"],
                        is_bijective=mapping_result["is_bijective"],
                        sample_mappings=mapping_result["sample_mappings"],
                        confidence=mapping_result["confidence"],
                    ))

        return mappings

    def _check_bijective_mapping(
        self,
        values_a: List[Any],
        values_b: List[Any]
    ) -> Dict[str, Any]:
        """ë‘ ì»¬ëŸ¼ì´ 1:1 ë§¤í•‘ì¸ì§€ í™•ì¸"""
        # ê°™ì€ rowì˜ ê°’ ìŒìœ¼ë¡œ ë§¤í•‘ êµ¬ì¶•
        forward_map = {}  # a â†’ b
        reverse_map = {}  # b â†’ a

        valid_pairs = 0
        sample_mappings = []

        for va, vb in zip(values_a, values_b):
            if va is None or vb is None:
                continue

            sa = str(va).strip()
            sb = str(vb).strip()

            if not sa or not sb:
                continue

            valid_pairs += 1

            # Forward ë§¤í•‘ í™•ì¸
            if sa in forward_map:
                if forward_map[sa] != sb:
                    # 1:N ê´€ê³„ - ë§¤í•‘ ì•„ë‹˜
                    return {"is_mapping": False}
            else:
                forward_map[sa] = sb
                if len(sample_mappings) < 20:
                    sample_mappings.append((sa, sb))

            # Reverse ë§¤í•‘ í™•ì¸
            if sb in reverse_map:
                if reverse_map[sb] != sa:
                    # N:1 ê´€ê³„ - ë‹¨ë°©í–¥ ë§¤í•‘
                    pass  # ê³„ì† ì§„í–‰
            else:
                reverse_map[sb] = sa

        if len(forward_map) < 3:
            return {"is_mapping": False}

        # Bijective í™•ì¸ (ì–‘ë°©í–¥ 1:1)
        is_bijective = len(forward_map) == len(reverse_map)

        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = min(len(forward_map) / 20, 1.0) * (0.95 if is_bijective else 0.7)

        return {
            "is_mapping": True,
            "mapping_count": len(forward_map),
            "is_bijective": is_bijective,
            "sample_mappings": sample_mappings,
            "confidence": confidence,
        }


# =============================================================================
# Cross-Table Pattern Matcher
# =============================================================================

class CrossTablePatternMatcher:
    """
    ë‹¤ë¥¸ í…Œì´ë¸” ê°„ íŒ¨í„´ ìœ ì‚¬ì„± ë¶„ì„

    ê°’ì´ ì§ì ‘ ê²¹ì¹˜ì§€ ì•Šì•„ë„ íŒ¨í„´ì´ ê°™ìœ¼ë©´
    ê°™ì€ ë„ë©”ì¸ì˜ ë‹¤ë¥¸ ì½”ë“œ ì²´ê³„ì¼ ìˆ˜ ìˆìŒ
    """

    def find_pattern_matches(
        self,
        patterns: Dict[str, ValuePattern],
        tables_data: Dict[str, Dict[str, List[Any]]]
    ) -> List[CrossTablePatternMatch]:
        """íŒ¨í„´ì´ ìœ ì‚¬í•œ í¬ë¡œìŠ¤ í…Œì´ë¸” ì»¬ëŸ¼ ìŒ ì°¾ê¸°"""
        matches = []

        # ì½”ë“œì„± ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        code_columns = [
            (key, pattern) for key, pattern in patterns.items()
            if pattern.is_likely_code or pattern.is_likely_identifier
        ]

        for i, (key_a, pattern_a) in enumerate(code_columns):
            table_a, col_a = key_a.split(".", 1)

            for key_b, pattern_b in code_columns[i+1:]:
                table_b, col_b = key_b.split(".", 1)

                # ê°™ì€ í…Œì´ë¸”ì€ ìŠ¤í‚µ (SameTableMappingDetectorê°€ ì²˜ë¦¬)
                if table_a == table_b:
                    continue

                # íŒ¨í„´ ë¹„êµ
                length_match = pattern_a.dominant_length == pattern_b.dominant_length
                char_type_match = pattern_a.dominant_char_type == pattern_b.dominant_char_type
                structure_match = pattern_a.dominant_structure == pattern_b.dominant_structure

                # ê°’ ê²¹ì¹¨ í™•ì¸
                values_a = set(str(v).strip() for v in tables_data[table_a][col_a] if v)
                values_b = set(str(v).strip() for v in tables_data[table_b][col_b] if v)

                intersection = values_a & values_b
                overlap_ratio = len(intersection) / min(len(values_a), len(values_b)) if values_a and values_b else 0

                # íŒ¨í„´ì´ ìœ ì‚¬í•˜ë©´ ê¸°ë¡ (ê°’ì´ ê²¹ì¹˜ë“  ì•ˆ ê²¹ì¹˜ë“ )
                if char_type_match and (length_match or structure_match):
                    matches.append(CrossTablePatternMatch(
                        table_a=table_a,
                        column_a=col_a,
                        table_b=table_b,
                        column_b=col_b,
                        pattern_match=f"{pattern_a.dominant_length}_{pattern_a.dominant_char_type}",
                        length_match=length_match,
                        char_type_match=char_type_match,
                        structure_match=structure_match,
                        has_value_overlap=overlap_ratio > 0.1,
                        overlap_ratio=overlap_ratio,
                    ))

        return matches


# =============================================================================
# LLM Context Generator (í•µì‹¬!)
# =============================================================================

class PatternAnalysisContextGenerator:
    """
    LLMì„ ìœ„í•œ íŒ¨í„´ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±

    ì•Œê³ ë¦¬ì¦˜ ë¶„ì„ ê²°ê³¼ë¥¼ LLMì´ í•´ì„í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ í¬ë§·íŒ…
    ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ ì—†ì´, LLMì´ ì¶”ë¡ í•˜ë„ë¡ ìœ ë„
    """

    def generate_context(
        self,
        patterns: Dict[str, ValuePattern],
        same_table_mappings: List[SameTableMapping],
        cross_table_matches: List[CrossTablePatternMatch],
    ) -> str:
        """LLMìš© ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        sections = []

        # 1. íŒ¨í„´ ê¸°ë°˜ ì»¬ëŸ¼ ê·¸ë£¹
        sections.append(self._generate_pattern_groups(patterns))

        # 2. Bridge Table í›„ë³´ (ê°™ì€ í…Œì´ë¸” ë‚´ ë§¤í•‘)
        sections.append(self._generate_bridge_table_section(same_table_mappings))

        # 3. í¬ë¡œìŠ¤ í…Œì´ë¸” íŒ¨í„´ ë§¤ì¹­
        sections.append(self._generate_cross_table_section(cross_table_matches))

        # 4. ë¶„ì„ ì§€ì¹¨
        sections.append(self._generate_analysis_instructions())

        return "\n\n".join(sections)

    def _generate_pattern_groups(self, patterns: Dict[str, ValuePattern]) -> str:
        """íŒ¨í„´ë³„ ì»¬ëŸ¼ ê·¸ë£¹"""
        output = ["## ğŸ“Š Value Pattern Analysis"]
        output.append("ê° ì»¬ëŸ¼ì˜ ê°’ íŒ¨í„´ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ê°™ì€ íŒ¨í„´ì€ ê°™ì€ ë„ë©”ì¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")

        # íŒ¨í„´ë³„ë¡œ ê·¸ë£¹í™”
        groups = defaultdict(list)
        for key, pattern in patterns.items():
            if pattern.is_likely_code or pattern.is_likely_identifier:
                group_key = f"{pattern.dominant_length}_{pattern.dominant_char_type}"
                groups[group_key].append((key, pattern))

        for group_key, members in sorted(groups.items(), key=lambda x: -len(x[1])):
            output.append(f"### Pattern: `{group_key}`")
            output.append(f"ì´ íŒ¨í„´ì„ ê°€ì§„ ì»¬ëŸ¼ë“¤ ({len(members)}ê°œ):\n")

            for key, pattern in members:
                output.append(f"- **{key}**")
                output.append(f"  - ìƒ˜í”Œ: {pattern.sample_values[:5]}")
                output.append(f"  - êµ¬ì¡°: `{pattern.dominant_structure}`")
                output.append(f"  - Unique ratio: {pattern.unique_ratio:.2f}")
            output.append("")

        return "\n".join(output)

    def _generate_bridge_table_section(self, mappings: List[SameTableMapping]) -> str:
        """Bridge Table í›„ë³´ ì„¹ì…˜"""
        output = ["## ğŸ”— Bridge Table Candidates (ê°™ì€ í…Œì´ë¸” ë‚´ 1:1 ë§¤í•‘)"]

        if not mappings:
            output.append("ë°œê²¬ëœ Bridge Table í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return "\n".join(output)

        output.append("ë‹¤ìŒ í…Œì´ë¸”ë“¤ì€ ì„œë¡œ ë‹¤ë¥¸ ì½”ë“œ ì²´ê³„ë¥¼ ë§¤í•‘í•˜ëŠ” ì—­í• ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")

        for m in mappings:
            output.append(f"### {m.table}")
            output.append(f"- **{m.column_a}** (`{m.pattern_a}`) â†” **{m.column_b}** (`{m.pattern_b}`)")
            output.append(f"- ë§¤í•‘ ìˆ˜: {m.mapping_count}, Bijective: {m.is_bijective}")
            output.append(f"- ì‹ ë¢°ë„: {m.confidence:.2f}")
            output.append(f"- ìƒ˜í”Œ ë§¤í•‘:")
            for sa, sb in m.sample_mappings[:5]:
                output.append(f"  - `{sa}` â†” `{sb}`")
            output.append("")

        return "\n".join(output)

    def _generate_cross_table_section(self, matches: List[CrossTablePatternMatch]) -> str:
        """í¬ë¡œìŠ¤ í…Œì´ë¸” íŒ¨í„´ ë§¤ì¹­ ì„¹ì…˜"""
        output = ["## ğŸ”€ Cross-Table Pattern Matches"]

        if not matches:
            output.append("íŒ¨í„´ì´ ìœ ì‚¬í•œ í¬ë¡œìŠ¤ í…Œì´ë¸” ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return "\n".join(output)

        output.append("ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ ìœ ì‚¬í•œ íŒ¨í„´ì„ ê°€ì§„ ì»¬ëŸ¼ë“¤ì…ë‹ˆë‹¤.\n")

        # ê°’ì´ ê²¹ì¹˜ëŠ” ê²ƒê³¼ ì•ˆ ê²¹ì¹˜ëŠ” ê²ƒ ë¶„ë¦¬
        with_overlap = [m for m in matches if m.has_value_overlap]
        without_overlap = [m for m in matches if not m.has_value_overlap]

        if with_overlap:
            output.append("### âœ… ê°’ì´ ì§ì ‘ ê²¹ì¹˜ëŠ” ìŒ (Direct FK í›„ë³´)")
            for m in with_overlap:
                output.append(f"- {m.table_a}.{m.column_a} â†” {m.table_b}.{m.column_b}")
                output.append(f"  - íŒ¨í„´: `{m.pattern_match}`, Overlap: {m.overlap_ratio:.2%}")
            output.append("")

        if without_overlap:
            output.append("### âš ï¸ ê°’ì€ ì•ˆ ê²¹ì¹˜ì§€ë§Œ íŒ¨í„´ì´ ìœ ì‚¬í•œ ìŒ (ê°„ì ‘ ê´€ê³„ ê°€ëŠ¥)")
            output.append("**ì´ ì»¬ëŸ¼ë“¤ì€ ê°™ì€ ë„ë©”ì¸ì˜ ë‹¤ë¥¸ ì½”ë“œ ì²´ê³„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**")
            output.append("**Bridge Tableì„ í†µí•´ ì—°ê²° ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ì„¸ìš”.**\n")

            for m in without_overlap:
                output.append(f"- {m.table_a}.{m.column_a} (pattern: `{m.pattern_match}`)")
                output.append(f"  â†” {m.table_b}.{m.column_b} (pattern: `{m.pattern_match}`)")
                output.append(f"  - Length match: {m.length_match}, Structure match: {m.structure_match}")
            output.append("")

        return "\n".join(output)

    def _generate_analysis_instructions(self) -> str:
        """LLM ë¶„ì„ ì§€ì¹¨"""
        return """## ğŸ“ ë¶„ì„ ì§€ì¹¨

ìœ„ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ íŒë‹¨í•´ì£¼ì„¸ìš”:

### 1. ê°™ì€ ë„ë©”ì¸ì˜ ë‹¤ë¥¸ ì½”ë“œ ì²´ê³„ ì‹ë³„
- íŒ¨í„´ì´ ìœ ì‚¬í•˜ì§€ë§Œ ê°’ì´ ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤ì´ ìˆë‚˜ìš”?
- ì˜ˆ: 2ê¸€ì ëŒ€ë¬¸ì vs 3ê¸€ì ëŒ€ë¬¸ìê°€ ê°™ì€ ì—”í‹°í‹°ì˜ ë‹¤ë¥¸ í‘œí˜„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- Bridge Tableì˜ ë§¤í•‘ì„ í†µí•´ ì—°ê²° ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ì„¸ìš”

### 2. ì˜ë¯¸ì  ì»¬ëŸ¼ ê·¸ë£¹í™”
- ì»¬ëŸ¼ëª…ê³¼ ê°’ íŒ¨í„´ì„ ì¢…í•©í•˜ì—¬ ê°™ì€ ê°œë…ì„ ì°¸ì¡°í•˜ëŠ” ì»¬ëŸ¼ë“¤ì„ ê·¸ë£¹í™”í•˜ì„¸ìš”
- ì»¬ëŸ¼ëª…ì´ ë‹¬ë¼ë„ ê°™ì€ ì—”í‹°í‹°ë¥¼ ê°€ë¦¬í‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤

### 3. ê°„ì ‘ FK ê´€ê³„ ë°œê²¬
- ì§ì ‘ ê°’ì´ ë§¤ì¹­ë˜ì§€ ì•Šì•„ë„ Bridge Tableì„ í†µí•´ ì—°ê²°ë˜ëŠ” ê´€ê³„ê°€ ìˆë‚˜ìš”?
- Join Pathë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”

### ì¶œë ¥ í˜•ì‹
```json
{
    "semantic_column_groups": [
        {
            "concept": "ì‹ë³„ëœ ê°œë… (ì˜ˆ: í•­ê³µì‚¬ ì½”ë“œ)",
            "columns": ["table1.col1", "table2.col2", ...],
            "code_systems": {
                "system_a": ["columns..."],
                "system_b": ["columns..."]
            },
            "bridge_table": "ë§¤í•‘ í…Œì´ë¸”ëª… ë˜ëŠ” null",
            "reasoning": "íŒë‹¨ ê·¼ê±°"
        }
    ],
    "indirect_relationships": [
        {
            "from": "table1.column1",
            "to": "table2.column2",
            "via": "bridge_table",
            "join_path": "table1.col1 â†’ bridge.col_a â†” bridge.col_b â† table2.col2",
            "reasoning": "íŒë‹¨ ê·¼ê±°"
        }
    ]
}
```"""


# =============================================================================
# Main Analyzer (í†µí•© ì§„ì…ì )
# =============================================================================

class EnhancedValuePatternAnalysis:
    """
    í–¥ìƒëœ ê°’ íŒ¨í„´ ë¶„ì„ (í†µí•© ì§„ì…ì )

    ì‚¬ìš©ë²•:
        analyzer = EnhancedValuePatternAnalysis()
        context = analyzer.analyze(tables_data)
        # contextë¥¼ LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨
    """

    def __init__(self):
        self.pattern_analyzer = ValuePatternAnalyzer()
        self.mapping_detector = SameTableMappingDetector(self.pattern_analyzer)
        self.cross_matcher = CrossTablePatternMatcher()
        self.context_generator = PatternAnalysisContextGenerator()

    def analyze(
        self,
        tables_data: Dict[str, Dict[str, List[Any]]]
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ë¶„ì„ ìˆ˜í–‰

        Returns:
            {
                "patterns": Dict[str, ValuePattern],
                "same_table_mappings": List[SameTableMapping],
                "cross_table_matches": List[CrossTablePatternMatch],
                "llm_context": str,  # LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  í…ìŠ¤íŠ¸
            }
        """
        # 1. ëª¨ë“  ì»¬ëŸ¼ íŒ¨í„´ ë¶„ì„
        patterns = self.pattern_analyzer.analyze_all_columns(tables_data)

        # 2. ê°™ì€ í…Œì´ë¸” ë‚´ ë§¤í•‘ íƒì§€ (Bridge Table í›„ë³´)
        same_table_mappings = self.mapping_detector.detect_mappings(tables_data, patterns)

        # 3. í¬ë¡œìŠ¤ í…Œì´ë¸” íŒ¨í„´ ë§¤ì¹­
        cross_table_matches = self.cross_matcher.find_pattern_matches(patterns, tables_data)

        # 4. LLM ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        llm_context = self.context_generator.generate_context(
            patterns, same_table_mappings, cross_table_matches
        )

        return {
            "patterns": patterns,
            "same_table_mappings": same_table_mappings,
            "cross_table_matches": cross_table_matches,
            "llm_context": llm_context,
        }

    def get_patterns_summary(self, patterns: Dict[str, ValuePattern]) -> Dict[str, List[str]]:
        """íŒ¨í„´ë³„ ì»¬ëŸ¼ ìš”ì•½"""
        summary = defaultdict(list)
        for key, pattern in patterns.items():
            if pattern.is_likely_code or pattern.is_likely_identifier:
                group = f"{pattern.dominant_length}_{pattern.dominant_char_type}"
                summary[group].append(key)
        return dict(summary)
